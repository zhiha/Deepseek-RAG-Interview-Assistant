{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6dabb81-759e-4b13-a07f-291a0ae2285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://chatapi.littlewheat.com/v1\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import uuid\n",
    "from typing import Annotated, Dict, List, Optional, Tuple, TypedDict\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from semantic_chunkers import StatisticalChunker\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "\n",
    "# load_dotenv()\n",
    "# OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-5Gh7IF83YlTd2plEZYJ6j1b9MO7jAwl7vjMYYsBIqrlpb0By' # os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_BASE\"] = 'https://chatapi.littlewheat.com/v1'\n",
    "#TavilySearch\n",
    "os.environ[\"TAVILY_API_KEY\"] = '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' #os.getenv('TAVILY_API_KEY')\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = 'sk-9a5987e251654e4691e63c25ab93df55'\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, base_url=os.environ[\"OPENAI_API_BASE\"])\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_base=\"https://chatapi.littlewheat.com/v1\", \n",
    "#                  openai_api_key=\"sk-5Gh7IF83YlTd2plEZYJ6j1b9MO7jAwl7vjMYYsBIqrlpb0By\")\n",
    "# llm = ChatOpenAI(model=\"deepseek-chat\", temperature=0, openai_api_base=\"https://api.deepseek.com\", \n",
    "#                  openai_api_key=\"sk-9a5987e251654e4691e63c25ab93df55\")\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(os.environ[\"OPENAI_API_BASE\"])\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", base_url=\"https://chatapi.littlewheat.com/v1\", \n",
    "                              openai_api_key=\"sk-5Gh7IF83YlTd2plEZYJ6j1b9MO7jAwl7vjMYYsBIqrlpb0By\")\n",
    "\n",
    "\n",
    "################################\n",
    "# Data Models Definition\n",
    "################################\n",
    "class Goals(BaseModel):\n",
    "    \"\"\"Structure for defining learning goals\"\"\"\n",
    "    goals: str = Field(None, description=\"Learning goals\")\n",
    "\n",
    "class LearningCheckpoint(BaseModel):\n",
    "    \"\"\"Structure for a single checkpoint\"\"\"\n",
    "    description: str = Field(..., description=\"Main checkpoint description\")\n",
    "    criteria: List[str] = Field(..., description=\"List of success criteria\")\n",
    "    verification: str = Field(..., description=\"How to verify this checkpoint\")\n",
    "\n",
    "class Checkpoints(BaseModel):\n",
    "    \"\"\"Main checkpoints container with index tracking\"\"\"\n",
    "    checkpoints: List[LearningCheckpoint] = Field(\n",
    "        ..., \n",
    "        description=\"List of checkpoints covering foundation, application, and mastery levels\"\n",
    "    )\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"Structure for search query collection\"\"\"\n",
    "    search_queries: list = Field(None, description=\"Search queries for retrieval.\")\n",
    "\n",
    "class LearningVerification(BaseModel):\n",
    "    \"\"\"Structure for verification results\"\"\"\n",
    "    understanding_level: float = Field(..., description=\"Understanding level of the student to the problem.\")\n",
    "    feedback: str\n",
    "    suggestions: List[str]\n",
    "    context_alignment: bool\n",
    "\n",
    "class FeynmanTeaching(BaseModel):\n",
    "    \"\"\"Structure for Feynman teaching method\"\"\"\n",
    "    simplified_explanation: str\n",
    "    key_concepts: List[str]\n",
    "    analogies: List[str]\n",
    "\n",
    "class QuestionOutput(BaseModel):\n",
    "    \"\"\"Structure for question generation output\"\"\"\n",
    "    question: str\n",
    "\n",
    "class InContext(BaseModel):\n",
    "    \"\"\"Structure for context verification\"\"\"\n",
    "    is_in_context: str = Field(..., description=\"Yes or No\")\n",
    "\n",
    "\n",
    "################################\n",
    "# Learning State Definition\n",
    "################################\n",
    "class LearningtState(TypedDict):\n",
    "    topic: str\n",
    "    goals: List[Goals]\n",
    "    context: str\n",
    "    context_chunks: Annotated[list, operator.add]\n",
    "    context_key: str\n",
    "    search_queries: SearchQuery\n",
    "    checkpoints: Checkpoints\n",
    "    verifications: LearningVerification\n",
    "    teachings: FeynmanTeaching\n",
    "    current_checkpoint: int\n",
    "    current_question: QuestionOutput\n",
    "    current_answer: str\n",
    "\n",
    "\n",
    "################################\n",
    "# Helper Functions\n",
    "################################\n",
    "def extract_content_from_chunks(chunks):\n",
    "    \"\"\"Extract and combine content from chunks with splits attribute.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of chunk objects that may contain splits attribute\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined content from all chunks joined with newlines\n",
    "    \"\"\"\n",
    "    content = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'splits') and chunk.splits:\n",
    "            chunk_content = ' '.join(chunk.splits)\n",
    "            content.append(chunk_content)\n",
    "    \n",
    "    return '\\n'.join(content)\n",
    "\n",
    "def format_checkpoints_as_message(checkpoints: Checkpoints) -> str:\n",
    "    \"\"\"Convert Checkpoints object to a formatted string for the message.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints (Checkpoints): Checkpoints object containing learning checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string containing numbered checkpoints with descriptions and criteria\n",
    "    \"\"\"\n",
    "    message = \"Here are the learning checkpoints:\\n\\n\"\n",
    "    for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "        message += f\"Checkpoint {i}:\\n\"\n",
    "        message += f\"Description: {checkpoint.description}\\n\"\n",
    "        message += \"Success Criteria:\\n\"\n",
    "        for criterion in checkpoint.criteria:\n",
    "            message += f\"- {criterion}\\n\"\n",
    "    return message\n",
    "\n",
    "def generate_checkpoint_message(checks: List[LearningCheckpoint]) -> HumanMessage:\n",
    "    \"\"\"Generate a formatted message for learning checkpoints that need context.\n",
    "    \n",
    "    Args:\n",
    "        checks (List[LearningCheckpoint]): List of learning checkpoint objects\n",
    "        \n",
    "    Returns:\n",
    "        HumanMessage: Formatted message containing checkpoint descriptions, criteria and \n",
    "                     verification methods, ready for context search\n",
    "    \"\"\"\n",
    "    formatted_checks = []\n",
    "    \n",
    "    for check in checks:\n",
    "        checkpoint_text = f\"\"\"\n",
    "        Description: {check.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f'- {criterion}' for criterion in check.criteria)}\n",
    "        Verification Method: {check.verification}\n",
    "        \"\"\"    # chr(10)å³'\\n'\n",
    "        formatted_checks.append(checkpoint_text)\n",
    "    \n",
    "    all_checks = \"\\n---\\n\".join(formatted_checks)\n",
    "    \n",
    "    checkpoints_message = HumanMessage(content=f\"\"\"The following learning checkpoints need additional context:\n",
    "        {all_checks}\n",
    "        \n",
    "        Please generate search queries to find relevant information.\"\"\")\n",
    "    \n",
    "    return checkpoints_message\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "# Prompts\n",
    "################################\n",
    "# æ ¹æ®å­¦ä¹ ææ–™ï¼Œç”Ÿæˆå­¦ä¹ æ£€æŸ¥ç‚¹\n",
    "learning_checkpoints_generator = SystemMessage(content=\"\"\"You will be given a learning topic title and learning objectives.\n",
    "Your goal is to generate clear learning checkpoints that will help verify understanding and progress through the topic.\n",
    "The output should be in the following dictionary structure:\n",
    "checkpoint \n",
    "-> description (level checkpoint description)\n",
    "-> criteria\n",
    "-> verification (How to verify this checkpoint (Feynman Methods))\n",
    "Requirements for each checkpoint:\n",
    "- Description should be clear and concise\n",
    "- Criteria should be specific and measurable (3-5 items)\n",
    "- Verification method should be practical and appropriate for the level\n",
    "- Verification will be checked by language model, so it must by in natural language\n",
    "- All elements should align with the learning objectives\n",
    "- Use action verbs and clear language\n",
    "Ensure all checkpoints progress logically from foundation to mastery.\n",
    "IMPORTANT - ANSWER ONLY 3 CHECKPOINTS\"\"\")\n",
    "\n",
    "# ç»™å®šæ£€æŸ¥ç‚¹ï¼Œç”Ÿæˆä¸€æ¡æ£€ç´¢å‘½ä»¤ï¼Œç”¨äºæŸ¥è¯¢è¯¥æ£€æŸ¥ç‚¹çš„è¾¾æˆæ ‡å‡†\n",
    "checkpoint_based_query_generator = SystemMessage(content=\"\"\"You will be given learning checkpoints for a topic.\n",
    "Your goal is to generate search queries that will retrieve content matching each checkpoint's requirements from retrieval systems or web search.\n",
    "Follow these steps:\n",
    "1. Analyze each learning checkpoint carefully\n",
    "2. For each checkpoint, generate ONE targeted search query that will retrieve:\n",
    "   - Content for checkpoint verification\n",
    "IMPORTANT: you should give me a structured answer, where the content string is in a single array, \n",
    "and the string is surrounded by quotation mark, i.e. format your answer like this: [\"the content\"]\n",
    "\"\"\")\n",
    "\n",
    "# ç»™å®šä¸€ä¸ªæ ‡å‡†åŠå…¶ä¸Šä¸‹æ–‡ï¼Œæ£€æŸ¥è¯¥æ ‡å‡†æ˜¯å¦è¢«ä¸Šä¸‹æ–‡å›ç­”\n",
    "validate_context = SystemMessage(content=\"\"\"You will be given a learning criteria and context.\n",
    "Check if the the criteria could be answered using the context.\n",
    "Always answer YES or NO\"\"\")\n",
    "\n",
    "# ç»™å®šæ£€æŸ¥ç‚¹ã€æˆåŠŸæ ‡å‡†ã€æ£€æµ‹æ–¹æ³•ï¼Œç”Ÿæˆä¸€ä¸ªé—®é¢˜ï¼Œèƒ½å¤Ÿç”¨äºæµ‹éªŒå­¦ç”Ÿæ˜¯å¦è¾¾æˆè¯¥æ£€æŸ¥ç‚¹çš„è¦æ±‚\n",
    "question_generator = SystemMessage(content=\"\"\"You will be given a checkpoint description, success criteria, and verification method.\n",
    "Your goal is to generate an appropriate question that aligns with the checkpoint's verification requirements.\n",
    "The question should:\n",
    "1. Follow the specified verification method\n",
    "2. Cover all success criteria\n",
    "3. Encourage demonstration of understanding\n",
    "4. Be clear and specific\n",
    "Output should be a single, well-formulated question that effectively tests the checkpoint's learning objectives.\"\"\")\n",
    "\n",
    "# ç»™å®šå­¦ç”Ÿçš„å›ç­”ï¼Œåˆ†æå…¶æ˜¯å¦åˆ°è¾¾äº†æ£€æŸ¥ç‚¹çš„æ ‡å‡†\n",
    "answer_verifier = SystemMessage(content=\"\"\"You will be given a student's answer, question, checkpoint details, and relevant context.\n",
    "Your goal is to analyze the answer against the checkpoint criteria and provided context.\n",
    "Analyze considering:\n",
    "1. Alignment with verification method specified\n",
    "2. Coverage of all success criteria\n",
    "3. Use of relevant concepts from context\n",
    "4. Depth and accuracy of understanding\n",
    "Output should include:\n",
    "- understanding_level: float between 0 and 1\n",
    "- feedback: detailed explanation of the assessment\n",
    "- suggestions: list of specific improvements\n",
    "- context_alignment: boolean indicating if the answer aligns with provided context\"\"\")\n",
    "\n",
    "# ç»™å®šæ£€æµ‹ç»“æœã€å­¦ä¹ çš„ä¸Šä¸‹æ–‡ï¼Œç»™å­¦ç”Ÿæå‡ºè¿˜éœ€åŠ å¼ºçš„çŸ¥è¯†ç‚¹ï¼ˆç”¨è´¹æ›¼å­¦ä¹ æ³•ï¼‰\n",
    "feynman_teacher = SystemMessage(content=\"\"\"You will be given verification results, checkpoint criteria, and learning context.\n",
    "Your goal is to create a Feynman-style teaching explanation for concepts that need reinforcement.\n",
    "The explanation should include:\n",
    "1. Simplified explanation without technical jargon\n",
    "2. Concrete, relatable analogies\n",
    "3. Key concepts to remember\n",
    "Output should follow the Feynman technique:\n",
    "- simplified_explanation: clear, jargon-free explanation\n",
    "- key_concepts: list of essential points\n",
    "- analogies: list of relevant, concrete comparisons\n",
    "Focus on making complex ideas accessible and memorable.\"\"\")\n",
    "\n",
    "\n",
    "################################\n",
    "# Context Storage\n",
    "################################\n",
    "class ContextStore:\n",
    "    \"\"\"Store for managing context chunks and their embeddings in memory.\n",
    "    \n",
    "    A class that provides storage and retrieval of context data using an in-memory store.\n",
    "    Each context entry consists of context chunks and their corresponding embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize ContextStore with an empty in-memory store.\"\"\"\n",
    "        self.store = InMemoryStore()\n",
    "        \n",
    "    def save_context(self, context_chunks: list, embeddings: list, key: str = None):\n",
    "        \"\"\"Save context chunks and their embeddings to the store.\n",
    "        \n",
    "        Args:\n",
    "            context_chunks (list): List of context chunk objects\n",
    "            embeddings (list): List of corresponding embeddings for the chunks\n",
    "            key (str, optional): Custom key for storing the context. Defaults to None,\n",
    "                               in which case a UUID is generated.\n",
    "            \n",
    "        Returns:\n",
    "            str: The key used to store the context\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        \n",
    "        if key is None:\n",
    "            key = str(uuid.uuid4())\n",
    "            \n",
    "        value = {\n",
    "            \"chunks\": context_chunks,\n",
    "            \"embeddings\": embeddings\n",
    "        }\n",
    "        \n",
    "        self.store.put(namespace, key, value)\n",
    "        return key\n",
    "        \n",
    "    def get_context(self, context_key: str):\n",
    "        \"\"\"Retrieve context data from the store using a key.\n",
    "        \n",
    "        Args:\n",
    "            context_key (str): The key used to store the context\n",
    "            \n",
    "        Returns:\n",
    "            dict: The stored context value containing chunks and embeddings\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        memory = self.store.get(namespace, context_key)\n",
    "        return memory.value\n",
    "\n",
    "\n",
    "################################\n",
    "# Learning Verification & Support\n",
    "################################\n",
    "# è°ƒç”¨æ¨¡å‹ï¼Œæ ¹æ®æ£€æŸ¥ç‚¹ï¼Œç”Ÿæˆä¸€æ¡query\n",
    "def generate_query(state: LearningtState):\n",
    "    \"\"\"Generates search queries based on learning checkpoints from current state.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(SearchQuery) \n",
    "    checkpoints_message = HumanMessage(content=format_checkpoints_as_message(state['checkpoints']))  \n",
    "    messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "    search_queries = structured_llm.invoke(messages)\n",
    "    return {\"search_queries\": search_queries}\n",
    "\n",
    "# \n",
    "def search_web(state: LearningtState):\n",
    "    \"\"\"Retrieves and processes web search results based on search queries.\"\"\"\n",
    "    search_queries = state[\"search_queries\"].search_queries\n",
    "    \n",
    "    all_search_docs = []\n",
    "    for query in search_queries:\n",
    "        search_docs = tavily_search.invoke(query)\n",
    "        all_search_docs.extend(search_docs)\n",
    "    \n",
    "    formatted_search_docs = [\n",
    "        f'Context: {doc[\"content\"]}\\n Source: {doc[\"url\"]}\\n'\n",
    "        for doc in all_search_docs\n",
    "    ]\n",
    "\n",
    "    chunk_embeddings = embeddings.embed_documents(formatted_search_docs)\n",
    "    context_key = context_store.save_context(\n",
    "        formatted_search_docs,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    \n",
    "    return {\"context_chunks\": formatted_search_docs}\n",
    "\n",
    "def generate_checkpoints(state: LearningtState):\n",
    "    \"\"\"Creates learning checkpoints based on given topic and goals.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(Checkpoints)\n",
    "    messages = [\n",
    "        learning_checkpoints_generator,\n",
    "        HumanMessage(content=f\"Topic: {state['topic']}\\nGoals: {', '.join(str(goal) for goal in state['goals'])}\"),\n",
    "    ]\n",
    "    checkpoints = structured_llm.invoke(messages)\n",
    "    return {\"checkpoints\": checkpoints}\n",
    "\n",
    "def chunk_context(state: LearningtState):\n",
    "    \"\"\"Splits context into manageable chunks and generates their embeddings.\"\"\"\n",
    "    encoder = OpenAIEncoder(name=\"text-embedding-3-large\", openai_base_url=\"https://chatapi.littlewheat.com/v1\")\n",
    "    chunker = StatisticalChunker(\n",
    "        encoder=encoder,\n",
    "        min_split_tokens=128,\n",
    "        max_split_tokens=512\n",
    "    )\n",
    "    \n",
    "    chunks = chunker([state['context']])\n",
    "    content = []\n",
    "    for chunk in chunks:\n",
    "        content.append(extract_content_from_chunks(chunk))\n",
    "\n",
    "    chunk_embeddings = embeddings.embed_documents(content)\n",
    "    context_key = context_store.save_context(\n",
    "        content,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    return {\"context_chunks\": content, \"context_key\": context_key}\n",
    "\n",
    "def context_validation(state: LearningtState):\n",
    "    \"\"\"Validates context coverage against checkpoint criteria using stored embeddings.\"\"\"\n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    checks = []\n",
    "    structured_llm = llm.with_structured_output(InContext)\n",
    "    \n",
    "    for checkpoint in state['checkpoints'].checkpoints:\n",
    "        query = embeddings.embed_query(checkpoint.verification)\n",
    "        \n",
    "        similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "        top_3_indices = sorted(range(len(similarities)), \n",
    "                             key=lambda i: similarities[i], \n",
    "                             reverse=True)[:3]\n",
    "        relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "        \n",
    "        messages = [\n",
    "            validate_context,\n",
    "            HumanMessage(content=f\"\"\"\n",
    "            Criteria:\n",
    "            {chr(10).join(f\"- {c}\" for c in checkpoint.criteria)}\n",
    "            \n",
    "            Context:\n",
    "            {chr(10).join(relevant_chunks)}\n",
    "            \"\"\")\n",
    "        ]\n",
    "        \n",
    "        response = structured_llm.invoke(messages)\n",
    "        if response.is_in_context.lower() == \"no\":\n",
    "            checks.append(checkpoint)\n",
    "    \n",
    "    if checks:\n",
    "        structured_llm = llm.with_structured_output(SearchQuery)\n",
    "        checkpoints_message = generate_checkpoint_message(checks)\n",
    "        \n",
    "        messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "        search_queries = structured_llm.invoke(messages)\n",
    "        return {\"search_queries\": search_queries}\n",
    "    \n",
    "    return {\"search_queries\": None}\n",
    "\n",
    "def generate_question(state: LearningtState):\n",
    "    \"\"\"Generates assessment questions based on current checkpoint verification requirements.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(QuestionOutput)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        question_generator,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Generate an appropriate verification question.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    question_output = structured_llm.invoke(messages)\n",
    "    return {\"current_question\": question_output.question}\n",
    "\n",
    "def verify_answer(state: LearningtState):\n",
    "    \"\"\"Evaluates user answers against checkpoint criteria using relevant context chunks.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(LearningVerification)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    query = embeddings.embed_query(checkpoint_info.verification)\n",
    "    \n",
    "    similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "    top_3_indices = sorted(range(len(similarities)), \n",
    "                         key=lambda i: similarities[i], \n",
    "                         reverse=True)[:3]\n",
    "    relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "    \n",
    "    messages = [\n",
    "        answer_verifier,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Question: {state['current_question']}\n",
    "        Answer: {state['current_answer']}\n",
    "        \n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Context:\n",
    "        {chr(10).join(relevant_chunks)}\n",
    "        \n",
    "        Assess the answer.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    verification = structured_llm.invoke(messages)\n",
    "    return {\"verifications\": verification}\n",
    "    \n",
    "def teach_concept(state: LearningtState):\n",
    "    \"\"\"Creates simplified Feynman-style explanations for concepts that need reinforcement.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(FeynmanTeaching)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        feynman_teacher,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Criteria: {checkpoint_info.criteria}\n",
    "        Verification: {state['verifications']}\n",
    "        \n",
    "        Context:\n",
    "        {state['context_chunks']}\n",
    "        \n",
    "        Create a Feynman teaching explanation.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    teaching = structured_llm.invoke(messages)\n",
    "    return {\"teachings\": teaching}\n",
    "\n",
    "\n",
    "################################\n",
    "# Helper State Management\n",
    "################################\n",
    "def user_answer(state: LearningtState):\n",
    "    \"\"\"Placeholder for handling user's answer input.\"\"\"\n",
    "    pass\n",
    "\n",
    "def next_checkpoint(state: LearningtState):\n",
    "    \"\"\"Advances to the next checkpoint in the learning sequence.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint'] + 1\n",
    "    return {'current_checkpoint': current_checkpoint}\n",
    "\n",
    "\n",
    "################################\n",
    "# Routing Logic\n",
    "################################\n",
    "def route_context(state: LearningtState):\n",
    "    \"\"\"Determines whether to process existing context or generate new search queries.\"\"\"\n",
    "    if state.get(\"context\"):\n",
    "        return 'chunk_context'\n",
    "    return 'generate_query'\n",
    "\n",
    "def route_verification(state: LearningtState):\n",
    "    \"\"\"Determines next step based on verification results and checkpoint progress.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    \n",
    "    if state['verifications'].understanding_level < 0.7:\n",
    "        return 'teach_concept'\n",
    "        \n",
    "    if current_checkpoint + 1 < len(state['checkpoints'].checkpoints):\n",
    "        return 'next_checkpoint'\n",
    "    \n",
    "    return END\n",
    "\n",
    "def route_teaching(state: LearningtState):\n",
    "    \"\"\"Routes to next checkpoint or ends session after teaching intervention.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    if current_checkpoint + 1 < len(state['checkpoints'].checkpoints):\n",
    "        return 'next_checkpoint'\n",
    "    return END\n",
    "\n",
    "def route_search(state: LearningtState):\n",
    "    \"\"\"Directs flow between question generation and web search based on query status.\"\"\"\n",
    "    if state['search_queries'] is None:\n",
    "        return \"generate_question\"\n",
    "    return \"search_web\"\n",
    "        \n",
    "searcher = StateGraph(LearningtState)\n",
    "memory = MemorySaver()\n",
    "context_store = ContextStore()\n",
    "\n",
    "searcher.add_node(\"generate_query\", generate_query)\n",
    "searcher.add_node(\"search_web\", search_web)\n",
    "searcher.add_node(\"chunk_context\", chunk_context)\n",
    "searcher.add_node(\"context_validation\", context_validation)\n",
    "searcher.add_node(\"generate_checkpoints\", generate_checkpoints)\n",
    "searcher.add_node(\"generate_question\", generate_question)\n",
    "searcher.add_node(\"next_checkpoint\", next_checkpoint)\n",
    "searcher.add_node(\"user_answer\", user_answer)\n",
    "searcher.add_node(\"verify_answer\", verify_answer)\n",
    "searcher.add_node(\"teach_concept\", teach_concept)\n",
    "\n",
    "# Flow\n",
    "searcher.add_edge(START, \"generate_checkpoints\")\n",
    "searcher.add_conditional_edges('generate_checkpoints', route_context,['chunk_context', 'generate_query'])\n",
    "searcher.add_edge(\"generate_query\", \"search_web\")\n",
    "searcher.add_edge(\"search_web\", \"generate_question\")\n",
    "searcher.add_edge(\"chunk_context\", 'context_validation')\n",
    "searcher.add_conditional_edges('context_validation', route_search,['search_web', 'generate_question'])\n",
    "\n",
    "searcher.add_edge(\"generate_question\", \"user_answer\")\n",
    "searcher.add_edge(\"user_answer\", \"verify_answer\")\n",
    "searcher.add_conditional_edges(\n",
    "    \"verify_answer\",\n",
    "    route_verification,\n",
    "    {\n",
    "        \"next_checkpoint\": \"next_checkpoint\",\n",
    "        \"teach_concept\": \"teach_concept\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "searcher.add_conditional_edges(\n",
    "    \"teach_concept\",\n",
    "    route_teaching,\n",
    "    {\n",
    "        \"next_checkpoint\": \"next_checkpoint\",\n",
    "        END: END\n",
    "        }\n",
    ")\n",
    "searcher.add_edge(\"next_checkpoint\", \"generate_question\")\n",
    "\n",
    "graph = searcher.compile(interrupt_after=[\"generate_checkpoints\"], interrupt_before=[\"user_answer\"], checkpointer=memory)\n",
    "\n",
    "# display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee853af9-d40f-44ff-a1a0-b688b10c5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# å­¦ä¹ åŒ»å­¦ç¬”è®°ï¼šè´«è¡€\n",
    "\n",
    "################################\n",
    "# Pretty print helper functions\n",
    "################################\n",
    "def print_checkpoints(event):\n",
    "    \"\"\"Pretty print checkpoints information with improved visual formatting\"\"\"\n",
    "    checkpoints = event.get('checkpoints', '')\n",
    "    if checkpoints:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ğŸ¯ LEARNING CHECKPOINTS OVERVIEW\".center(80))\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "            # Checkpoint header with number\n",
    "            print(f\"ğŸ“ CHECKPOINT #{i}\".center(80))\n",
    "            print(\"â”€\" * 80 + \"\\n\")\n",
    "            \n",
    "            # Description section with text wrapping\n",
    "            print(\"ğŸ“ Description:\")\n",
    "            print(\"â”€\" * 40)\n",
    "            words = checkpoint.description.split()\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 70:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    print(f\"  {' '.join(current_line)}\")\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                print(f\"  {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Success Criteria section\n",
    "            print(\"âœ… Success Criteria:\")\n",
    "            print(\"â”€\" * 40)\n",
    "            for j, criterion in enumerate(checkpoint.criteria, 1):\n",
    "                # Wrap each criterion text\n",
    "                words = criterion.split()\n",
    "                current_line = []\n",
    "                current_length = 0\n",
    "                first_line = True\n",
    "                \n",
    "                for word in words:\n",
    "                    if current_length + len(word) + 1 <= 66:  # Shorter width to account for numbering\n",
    "                        current_line.append(word)\n",
    "                        current_length += len(word) + 1\n",
    "                    else:\n",
    "                        if first_line:\n",
    "                            print(f\"  {j}. {' '.join(current_line)}\")\n",
    "                            first_line = False\n",
    "                        else:\n",
    "                            print(f\"     {' '.join(current_line)}\")\n",
    "                        current_line = [word]\n",
    "                        current_length = len(word)\n",
    "                \n",
    "                if current_line:\n",
    "                    if first_line:\n",
    "                        print(f\"  {j}. {' '.join(current_line)}\")\n",
    "                    else:\n",
    "                        print(f\"     {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Verification Method section\n",
    "            print(\"ğŸ” Verification Method:\")\n",
    "            print(\"â”€\" * 40)\n",
    "            words = checkpoint.verification.split()\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 70:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    print(f\"  {' '.join(current_line)}\")\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                print(f\"  {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Separator between checkpoints\n",
    "            if i < len(checkpoints.checkpoints):\n",
    "                print(\"~\" * 80 + \"\\n\")\n",
    "        \n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "def print_verification_results(event):\n",
    "    \"\"\"Pretty print verification results with improved formatting\"\"\"\n",
    "    verifications = event.get('verifications', '')\n",
    "    if verifications:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ğŸ“Š VERIFICATION RESULTS\".center(50))\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "        # Understanding Level with visual bar\n",
    "        understanding = verifications.understanding_level\n",
    "        bar_length = 20\n",
    "        filled_length = int(understanding * bar_length)\n",
    "        bar = \"â–ˆ\" * filled_length + \"â–‘\" * (bar_length - filled_length)\n",
    "        \n",
    "        print(f\"ğŸ“ˆ Understanding Level: [{bar}] {understanding * 100:.1f}%\\n\")\n",
    "        \n",
    "        # Feedback section\n",
    "        print(\"ğŸ’¡ Feedback:\")\n",
    "        print(f\"{verifications.feedback}\\n\")\n",
    "        \n",
    "        # Suggestions section\n",
    "        print(\"ğŸ¯ Suggestions:\")\n",
    "        for i, suggestion in enumerate(verifications.suggestions, 1):\n",
    "            print(f\"  {i}. {suggestion}\")\n",
    "        print()\n",
    "        \n",
    "        # Context Alignment\n",
    "        print(\"ğŸ” Context Alignment:\")\n",
    "        print(f\"{verifications.context_alignment}\\n\")\n",
    "        \n",
    "        print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "def print_teaching_results(event):\n",
    "    \"\"\"Pretty print Feynman teaching results with improved formatting\"\"\"\n",
    "    teachings = event.get('teachings', '')\n",
    "    if teachings:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"ğŸ“ FEYNMAN TEACHING EXPLANATION\".center(70))\n",
    "        print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "        # Simplified Explanation section\n",
    "        print(\"ğŸ“š SIMPLIFIED EXPLANATION:\")\n",
    "        print(\"â”€\" * 30)\n",
    "        # Split explanation into paragraphs for better readability\n",
    "        paragraphs = teachings.simplified_explanation.split('\\n')\n",
    "        for paragraph in paragraphs:\n",
    "            # Wrap text at 60 characters for better readability\n",
    "            words = paragraph.split()\n",
    "            lines = []\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 60:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    lines.append(' '.join(current_line))\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                lines.append(' '.join(current_line))\n",
    "            \n",
    "            for line in lines:\n",
    "                print(f\"{line}\")\n",
    "            print()\n",
    "        \n",
    "        # Key Concepts section\n",
    "        print(\"ğŸ’¡ KEY CONCEPTS:\")\n",
    "        print(\"â”€\" * 30)\n",
    "        for i, concept in enumerate(teachings.key_concepts, 1):\n",
    "            print(f\"  {i}. {concept}\")\n",
    "        print()\n",
    "        \n",
    "        # Analogies section\n",
    "        print(\"ğŸ”„ ANALOGIES & EXAMPLES:\")\n",
    "        print(\"â”€\" * 30)\n",
    "        for i, analogy in enumerate(teachings.analogies, 1):\n",
    "            print(f\"  {i}. {analogy}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "        \n",
    "# note = \"\"\"Anemia: A Comprehensive Overview\n",
    "# Definition\n",
    "# Anemia is a medical condition characterized by a decrease in the total number of red blood cells (RBCs) or hemoglobin in the blood. This reduction leads to a diminished ability to carry oxygen to the body's tissues, affecting overall body function and health.\n",
    "# Blood Components and Their Role\n",
    "# Red blood cells, also known as erythrocytes, are fundamental components of blood that carry oxygen throughout the body. These cells contain hemoglobin, an iron-containing protein that gives blood its characteristic red color and is responsible for oxygen transport. The typical lifespan of a red blood cell is approximately 120 days, after which it must be replaced by new cells produced in the bone marrow.\n",
    "# Types of Anemia\n",
    "# Iron Deficiency Anemia represents the most prevalent form of anemia worldwide. It occurs due to insufficient iron intake or absorption, particularly affecting pregnant women, growing children, menstruating women, and individuals with poor nutritional intake.\n",
    "# Vitamin Deficiency Anemia develops when the body lacks sufficient amounts of vitamin B12 or folate (vitamin B9). This deficiency can stem from dietary inadequacies or problems with nutrient absorption in the digestive system.\n",
    "# Aplastic Anemia, though rare, presents a serious condition where the bone marrow fails to produce adequate blood cells. This form can be either inherited through genetic factors or acquired through various environmental causes or medical conditions.\n",
    "# Hemolytic Anemia occurs when red blood cells are destroyed at a rate faster than the body can replace them. This condition may be inherited through genetic factors or acquired through various external causes.\n",
    "# Clinical Manifestations\n",
    "# Anemia manifests through various symptoms including persistent fatigue and weakness. Patients often present with pale or yellowish skin, experience shortness of breath, and may suffer from dizziness. Additional symptoms include irregular heartbeat patterns, frequent headaches, cold extremities, and occasional chest pain.\n",
    "# Diagnostic Approach\n",
    "# Diagnosis begins with a thorough physical examination by a healthcare provider. Blood tests form the cornerstone of diagnosis, including a Complete Blood Count (CBC), assessment of iron levels, vitamin B12 measurement, and folate level determination. These tests help identify the specific type of anemia and guide appropriate treatment.\n",
    "# Treatment Strategies\n",
    "# Dietary modification serves as a fundamental treatment approach. This involves increasing consumption of iron-rich foods such as red meat, dark leafy vegetables, legumes, and iron-fortified cereals.\n",
    "# Supplementation often proves necessary and may include iron supplements, vitamin B12, or folic acid, depending on the underlying cause of anemia.\n",
    "# Medical interventions become necessary in severe cases. Blood transfusions may be required for severe anemia, while bone marrow transplantation might be considered for cases of aplastic anemia.\n",
    "# Preventive Measures\n",
    "# Prevention centers on maintaining a balanced diet rich in essential nutrients, particularly iron, vitamin B12, folate, and vitamin C, which enhances iron absorption. Regular medical check-ups allow for early detection and intervention.\n",
    "# Certain populations require special attention regarding prevention. These include pregnant women, menstruating women, growing children, individuals following vegetarian or vegan diets, and athletes who may have increased nutritional demands.\n",
    "# Potential Complications\n",
    "# Untreated anemia can lead to several serious complications. These include severe fatigue that impacts daily activities, complications during pregnancy, cardiovascular problems, depression, and cognitive difficulties that may affect work or school performance.\n",
    "# Clinical Significance\n",
    "# Anemia often serves as an indicator of other underlying medical conditions. Therefore, early detection and appropriate treatment prove crucial for optimal outcomes. Different forms of anemia require specific treatment approaches, and regular monitoring may be necessary to ensure treatment effectiveness.\"\"\"\n",
    "\n",
    "import fitz\n",
    "def pdf_to_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")  # ä»…æå–æ–‡æœ¬\n",
    "    return text\n",
    "\n",
    "note = pdf_to_text(\"æ­»é”çŸ¥è¯†æ€»ç»“.pdf\")\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435eebc1-5d60-4dcf-8733-a30a47171107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                        ğŸ¯ LEARNING CHECKPOINTS OVERVIEW                         \n",
      "================================================================================\n",
      "\n",
      "                                ğŸ“ CHECKPOINT #1                                 \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ Description:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ç†è§£æ­»é”çš„åŸºæœ¬æ¦‚å¿µå’Œå¿…è¦æ¡ä»¶\n",
      "\n",
      "âœ… Success Criteria:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. èƒ½å¤Ÿå®šä¹‰æ­»é”\n",
      "  2. èƒ½å¤Ÿåˆ—å‡ºæ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶\n",
      "  3. èƒ½å¤Ÿè§£é‡Šæ¯ä¸ªå¿…è¦æ¡ä»¶çš„ä½œç”¨\n",
      "\n",
      "ğŸ” Verification Method:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  è¯·è§£é‡Šä»€ä¹ˆæ˜¯æ­»é”ï¼Œå¹¶åˆ—å‡ºå¹¶è§£é‡Šæ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶ã€‚\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "                                ğŸ“ CHECKPOINT #2                                 \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ Description:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  èƒ½å¤Ÿè¯†åˆ«å’Œåˆ†ææ­»é”å‘ç”Ÿçš„åœºæ™¯\n",
      "\n",
      "âœ… Success Criteria:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. èƒ½å¤Ÿè¯†åˆ«å¯èƒ½å¯¼è‡´æ­»é”çš„ä»£ç ç‰‡æ®µ\n",
      "  2. èƒ½å¤Ÿåˆ†ææ­»é”å‘ç”Ÿçš„å…·ä½“åŸå› \n",
      "  3. èƒ½å¤Ÿæè¿°æ­»é”å‘ç”Ÿçš„æµç¨‹\n",
      "\n",
      "ğŸ” Verification Method:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  è¯·åˆ†æä»¥ä¸‹ä»£ç ç‰‡æ®µï¼ŒæŒ‡å‡ºæ˜¯å¦å­˜åœ¨æ­»é”é£é™©ï¼Œå¹¶è§£é‡ŠåŸå› ã€‚\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "                                ğŸ“ CHECKPOINT #3                                 \n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ Description:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  æŒæ¡æ­»é”çš„é¢„é˜²å’Œé¿å…ç­–ç•¥\n",
      "\n",
      "âœ… Success Criteria:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  1. èƒ½å¤Ÿåˆ—å‡ºå¸¸è§çš„æ­»é”é¢„é˜²ç­–ç•¥\n",
      "  2. èƒ½å¤Ÿè§£é‡Šæ¯ç§é¢„é˜²ç­–ç•¥çš„åŸç†\n",
      "  3. èƒ½å¤Ÿåº”ç”¨æ­»é”é¿å…ç®—æ³•\n",
      "\n",
      "ğŸ” Verification Method:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  è¯·åˆ—å‡ºå¹¶è§£é‡Šä¸‰ç§å¸¸è§çš„æ­»é”é¢„é˜²ç­–ç•¥ï¼Œå¹¶æè¿°å¦‚ä½•ä½¿ç”¨é“¶è¡Œå®¶ç®—æ³•æ¥é¿å…æ­»é”ã€‚\n",
      "\n",
      "================================================================================\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\n",
    "\"topic\": \"Anemia\",\n",
    "'goals': ['Im medical student, i want to master the diagnosis of Anemia'],\n",
    "'context': note,\n",
    "'current_checkpoint': 0}\n",
    "\n",
    "initial_input = {\n",
    "\"topic\": \"æ­»é”\",\n",
    "'goals': ['æˆ‘æ˜¯ä¸€åè®¡ç®—æœºä¸“ä¸šçš„å­¦ç”Ÿï¼Œå¸Œæœ›æŒæ¡æ­»é”ç›¸å…³çš„çŸ¥è¯†'],\n",
    "'context': note,\n",
    "'current_checkpoint': 0}\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"20\"}}\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print_checkpoints(event)\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91f1daf-ec0b-41c0-8799-a95431de8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints=[LearningCheckpoint(description='ç†è§£æ­»é”çš„åŸºæœ¬æ¦‚å¿µå’Œå¿…è¦æ¡ä»¶', criteria=['èƒ½å¤Ÿå®šä¹‰æ­»é”', 'èƒ½å¤Ÿåˆ—å‡ºæ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶', 'èƒ½å¤Ÿè§£é‡Šæ¯ä¸ªå¿…è¦æ¡ä»¶çš„ä½œç”¨'], verification='è¯·è§£é‡Šä»€ä¹ˆæ˜¯æ­»é”ï¼Œå¹¶åˆ—å‡ºå¹¶è§£é‡Šæ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶ã€‚'), LearningCheckpoint(description='èƒ½å¤Ÿè¯†åˆ«å’Œåˆ†ææ­»é”å‘ç”Ÿçš„åœºæ™¯', criteria=['èƒ½å¤Ÿè¯†åˆ«å¯èƒ½å¯¼è‡´æ­»é”çš„ä»£ç ç‰‡æ®µ', 'èƒ½å¤Ÿåˆ†ææ­»é”å‘ç”Ÿçš„å…·ä½“åŸå› ', 'èƒ½å¤Ÿæè¿°æ­»é”å‘ç”Ÿçš„æµç¨‹'], verification='è¯·åˆ†æä»¥ä¸‹ä»£ç ç‰‡æ®µï¼ŒæŒ‡å‡ºæ˜¯å¦å­˜åœ¨æ­»é”é£é™©ï¼Œå¹¶è§£é‡ŠåŸå› ã€‚'), LearningCheckpoint(description='æŒæ¡æ­»é”çš„é¢„é˜²å’Œé¿å…ç­–ç•¥', criteria=['èƒ½å¤Ÿåˆ—å‡ºå¸¸è§çš„æ­»é”é¢„é˜²ç­–ç•¥', 'èƒ½å¤Ÿè§£é‡Šæ¯ç§é¢„é˜²ç­–ç•¥çš„åŸç†', 'èƒ½å¤Ÿåº”ç”¨æ­»é”é¿å…ç®—æ³•'], verification='è¯·åˆ—å‡ºå¹¶è§£é‡Šä¸‰ç§å¸¸è§çš„æ­»é”é¢„é˜²ç­–ç•¥ï¼Œå¹¶æè¿°å¦‚ä½•ä½¿ç”¨é“¶è¡Œå®¶ç®—æ³•æ¥é¿å…æ­»é”ã€‚')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab269941049433491b2f09bd84f0a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<h3 style=\"margin: 0;\">Checkpoint 1</h3>'), Checkbox(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def create_checkpoint_editor(checkpoints_model: Checkpoints):\n",
    "    \"\"\"\n",
    "    Creates an interactive checkpoint editor using a Pydantic model.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints_model: Pydantic model of Checkpoints class\n",
    "    \"\"\"\n",
    "    # Convert to list of dictionaries for easier editing\n",
    "    checkpoints = [cp.model_dump() for cp in checkpoints_model.checkpoints]\n",
    "    checkpoints_widgets = []\n",
    "    accepted_checkpoints = []\n",
    "    \n",
    "    def create_criterion_widget(checkpoint_index: int, criterion_value: str = \"\", criterion_index: int = None):\n",
    "        \"\"\"Creates a widget for a single criterion with a delete button\"\"\"\n",
    "        criterion_container = widgets.HBox([\n",
    "            widgets.Text(\n",
    "                value=criterion_value,\n",
    "                description=f'{criterion_index + 1}.' if criterion_index is not None else 'New',\n",
    "                layout=widgets.Layout(width='85%')\n",
    "            ),\n",
    "            widgets.Button(\n",
    "                description='Delete',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(width='15%')\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        def on_criterion_change(change):\n",
    "            nonlocal criterion_index\n",
    "            if criterion_index is not None:\n",
    "                checkpoints[checkpoint_index]['criteria'][criterion_index] = change['new']\n",
    "        \n",
    "        def remove_criterion(b):\n",
    "            if criterion_index is not None:\n",
    "                checkpoints[checkpoint_index]['criteria'].pop(criterion_index)\n",
    "                update_checkpoint_widget(checkpoint_index)\n",
    "        \n",
    "        criterion_container.children[0].observe(on_criterion_change, names='value')\n",
    "        criterion_container.children[1].on_click(remove_criterion)\n",
    "        \n",
    "        return criterion_container\n",
    "    \n",
    "    def create_checkpoint_widget(checkpoint: dict, index: int):\n",
    "        \"\"\"Creates a widget for a single checkpoint\"\"\"\n",
    "        \n",
    "        def on_accept_change(change):\n",
    "            if change['new']:\n",
    "                accepted_checkpoints.append(index)\n",
    "            else:\n",
    "                if index in accepted_checkpoints:\n",
    "                    accepted_checkpoints.remove(index)\n",
    "        \n",
    "        def on_description_change(change):\n",
    "            checkpoints[index]['description'] = change['new']\n",
    "        \n",
    "        def on_verification_change(change):\n",
    "            checkpoints[index]['verification'] = change['new']\n",
    "        \n",
    "        def add_criterion(b):\n",
    "            checkpoints[index]['criteria'].append(\"\")\n",
    "            update_checkpoint_widget(index)\n",
    "        \n",
    "        def remove_checkpoint(b):\n",
    "            checkpoints.pop(index)\n",
    "            update_all_checkpoints()\n",
    "        \n",
    "        # Header with checkbox and delete button\n",
    "        header = widgets.HBox([\n",
    "            widgets.HTML(f'<h3 style=\"margin: 0;\">Checkpoint {index + 1}</h3>'),\n",
    "            widgets.Checkbox(\n",
    "                value=False,\n",
    "                description='Accept',\n",
    "                indent=False,\n",
    "                layout=widgets.Layout(margin='5px 0 0 20px')\n",
    "            ),\n",
    "            widgets.Button(\n",
    "                description='Delete checkpoint',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(margin='0 0 0 20px')\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Description\n",
    "        description = widgets.Textarea(\n",
    "            value=checkpoint['description'],\n",
    "            description='Description:',\n",
    "            layout=widgets.Layout(width='95%', height='60px')\n",
    "        )\n",
    "        \n",
    "        # Criteria\n",
    "        criteria_label = widgets.HTML('<b>Criteria:</b>')\n",
    "        criteria_container = widgets.VBox([\n",
    "            create_criterion_widget(index, criterion, i)\n",
    "            for i, criterion in enumerate(checkpoint['criteria'])\n",
    "        ])\n",
    "        \n",
    "        # Add criterion button\n",
    "        add_criterion_btn = widgets.Button(\n",
    "            description='Add criterion',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        # Verification\n",
    "        verification = widgets.Textarea(\n",
    "            value=checkpoint['verification'],\n",
    "            description='Verification:',\n",
    "            layout=widgets.Layout(width='95%', height='60px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        separator = widgets.HTML('<hr style=\"margin: 20px 0;\">')\n",
    "        \n",
    "        # Combine all elements\n",
    "        checkpoint_widget = widgets.VBox([\n",
    "            header,\n",
    "            description,\n",
    "            criteria_label,\n",
    "            criteria_container,\n",
    "            add_criterion_btn,\n",
    "            verification,\n",
    "            separator\n",
    "        ])\n",
    "        \n",
    "        # Add observers and handlers\n",
    "        header.children[1].observe(on_accept_change, names='value')\n",
    "        header.children[2].on_click(remove_checkpoint)\n",
    "        description.observe(on_description_change, names='value')\n",
    "        verification.observe(on_verification_change, names='value')\n",
    "        add_criterion_btn.on_click(add_criterion)\n",
    "        \n",
    "        return checkpoint_widget\n",
    "    \n",
    "    def update_checkpoint_widget(index: int):\n",
    "        \"\"\"Updates a single checkpoint widget\"\"\"\n",
    "        if 0 <= index < len(checkpoints):\n",
    "            checkpoints_widgets[index] = create_checkpoint_widget(checkpoints[index], index)\n",
    "            update_main_container()\n",
    "    \n",
    "    def update_all_checkpoints():\n",
    "        \"\"\"Updates all checkpoint widgets\"\"\"\n",
    "        nonlocal checkpoints_widgets\n",
    "        checkpoints_widgets = [\n",
    "            create_checkpoint_widget(checkpoint, i)\n",
    "            for i, checkpoint in enumerate(checkpoints)\n",
    "        ]\n",
    "        update_main_container()\n",
    "    \n",
    "    def add_new_checkpoint(b):\n",
    "        \"\"\"Adds a new checkpoint\"\"\"\n",
    "        checkpoints.append({\n",
    "            'description': '',\n",
    "            'criteria': [],\n",
    "            'verification': ''\n",
    "        })\n",
    "        update_all_checkpoints()\n",
    "    \n",
    "    def get_pydantic_model() -> Checkpoints:\n",
    "        \"\"\"Converts the current editor state back to a Pydantic model\"\"\"\n",
    "        return Checkpoints(checkpoints=[\n",
    "            LearningCheckpoint(**checkpoint)\n",
    "            for checkpoint in checkpoints\n",
    "        ])\n",
    "    \n",
    "    # Create initial checkpoint widgets\n",
    "    checkpoints_widgets = [\n",
    "        create_checkpoint_widget(checkpoint, i)\n",
    "        for i, checkpoint in enumerate(checkpoints)\n",
    "    ]\n",
    "    \n",
    "    # Add new checkpoint button\n",
    "    add_checkpoint_btn = widgets.Button(\n",
    "        description='Add checkpoint',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(margin='20px 0')\n",
    "    )\n",
    "    add_checkpoint_btn.on_click(add_new_checkpoint)\n",
    "    \n",
    "    # Main container\n",
    "    main_container = widgets.VBox(\n",
    "        checkpoints_widgets + [add_checkpoint_btn],\n",
    "        layout=widgets.Layout(\n",
    "            padding='20px',\n",
    "            border='1px solid #ddd',\n",
    "            border_radius='5px'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def update_main_container():\n",
    "        \"\"\"Updates the main container\"\"\"\n",
    "        main_container.children = tuple(checkpoints_widgets + [add_checkpoint_btn])\n",
    "    \n",
    "    # Add method to container to retrieve data later\n",
    "    main_container.get_model = get_pydantic_model\n",
    "    \n",
    "    return main_container\n",
    "\n",
    "\n",
    "checkpoints = event['checkpoints']\n",
    "print(checkpoints)\n",
    "editor = create_checkpoint_editor(checkpoints)\n",
    "display(editor)\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307c1fb7-7761-48ab-b3d1-3d5f7070eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-14 00:32:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 512. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113575c896dd49c0a459efa202dd2dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æ­»é”ï¼Œå¹¶åˆ—å‡ºå¹¶è§£é‡Šæ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶ã€‚\n"
     ]
    }
   ],
   "source": [
    "updated_model = editor.get_model()\n",
    "graph.update_state(thread, {\"checkpoints\": updated_model}, as_node=\"generate_checkpoints\")\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    # Review\n",
    "    current_question = event.get('current_question', '')\n",
    "    if current_question:\n",
    "        print(current_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0633b54a-a0d9-42b0-90ad-8c320603e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('verify_answer',)\n",
      "()\n",
      "('generate_question',)\n",
      "('user_answer',)\n",
      "\n",
      "==================================================\n",
      "              ğŸ“Š VERIFICATION RESULTS              \n",
      "==================================================\n",
      "\n",
      "ğŸ“ˆ Understanding Level: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘] 75.0%\n",
      "\n",
      "ğŸ’¡ Feedback:\n",
      "The student has a good understanding of the basic concept of deadlock and has correctly listed the four necessary conditions for deadlock. However, the explanation of each condition is lacking in depth and detail. The student should provide more specific explanations for each condition to demonstrate a deeper understanding.\n",
      "\n",
      "ğŸ¯ Suggestions:\n",
      "  1. Provide a more detailed explanation of each of the four necessary conditions for deadlock.\n",
      "  2. Explain how each condition contributes to the occurrence of deadlock.\n",
      "  3. Use examples or scenarios to illustrate the conditions and their impact on deadlock.\n",
      "\n",
      "ğŸ” Context Alignment:\n",
      "True\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_question = \"\"\"\n",
    "æ­»é”æ˜¯ä¸¤ä¸ªæˆ–æ›´å¤šè¿›ç¨‹åœ¨éœ€è¦ç›¸åŒèµ„æºæ—¶ï¼Œç”±äºç‰¹æ®Šç«äº‰æ¡ä»¶è€Œå‘ç”Ÿçš„ï¼Œé™·å…¥ç­‰å¾…èµ„æºä½†éƒ½æ— æ³•è¢«æ»¡è¶³çš„æƒ…å†µï¼Œå‘ç”Ÿæ­»é”åï¼Œå¤šä¸ªè¿›ç¨‹ä¼šé™·å…¥æ°¸ä¹…çš„ç­‰å¾…ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œã€‚\n",
    "å‘ç”Ÿæ­»é”çš„å››ä¸ªå¿…è¦æ¡ä»¶æ˜¯ï¼šäº’æ–¥ã€éæŠ¢å ã€å æœ‰å¹¶ç­‰å¾…ã€å¾ªç¯ç­‰å¾…ã€‚\n",
    "\"\"\"# input(\"Answer the question above: \")\n",
    "graph.update_state(thread, {\"current_answer\": answer_question}, as_node=\"user_answer\")\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(graph.get_state(thread).next)\n",
    "    \n",
    "print_verification_results(event)\n",
    "print_teaching_results(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c87239-15bc-4ad1-b8b9-d97ab41bfd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
