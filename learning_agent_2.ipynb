{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6dabb81-759e-4b13-a07f-291a0ae2285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://chatapi.littlewheat.com/v1\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import operator\n",
    "import uuid\n",
    "from typing import Annotated, Dict, List, Optional, Tuple, TypedDict\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from semantic_chunkers import StatisticalChunker\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "\n",
    "# load_dotenv()\n",
    "# OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-5Gh7IF83YlTd2plEZYJ6j1b9MO7jAwl7vjMYYsBIqrlpb0By' # os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_BASE\"] = 'https://chatapi.littlewheat.com/v1'\n",
    "#TavilySearch\n",
    "os.environ[\"TAVILY_API_KEY\"] = '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' #os.getenv('TAVILY_API_KEY')\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = 'sk-9a5987e251654e4691e63c25ab93df55'\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, base_url=os.environ[\"OPENAI_API_BASE\"])\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, openai_api_base=\"https://chatapi.littlewheat.com/v1\", \n",
    "#                  openai_api_key=\"sk-5Gh7IF83YlTd2plEZYJ6j1b9MO7jAwl7vjMYYsBIqrlpb0By\")\n",
    "# llm = ChatOpenAI(model=\"deepseek-chat\", temperature=0, openai_api_base=\"https://api.deepseek.com\", \n",
    "#                  openai_api_key=\"sk-9a5987e251654e4691e63c25ab93df55\")\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(os.environ[\"OPENAI_API_BASE\"])\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", base_url=\"https://chatapi.littlewheat.com/v1\", \n",
    "                              openai_api_key=\"sk-5Gh7IF83YlTd2plEZYJ6j1b9MO7jAwl7vjMYYsBIqrlpb0By\")\n",
    "\n",
    "\n",
    "################################\n",
    "# Data Models Definition\n",
    "################################\n",
    "class Goals(BaseModel):\n",
    "    \"\"\"Structure for defining learning goals\"\"\"\n",
    "    goals: str = Field(None, description=\"Learning goals\")\n",
    "\n",
    "class LearningCheckpoint(BaseModel):\n",
    "    \"\"\"Structure for a single checkpoint\"\"\"\n",
    "    description: str = Field(..., description=\"Main checkpoint description\")\n",
    "    criteria: List[str] = Field(..., description=\"List of success criteria\")\n",
    "    verification: str = Field(..., description=\"How to verify this checkpoint\")\n",
    "\n",
    "class Checkpoints(BaseModel):\n",
    "    \"\"\"Main checkpoints container with index tracking\"\"\"\n",
    "    checkpoints: List[LearningCheckpoint] = Field(\n",
    "        ..., \n",
    "        description=\"List of checkpoints covering foundation, application, and mastery levels\"\n",
    "    )\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    \"\"\"Structure for search query collection\"\"\"\n",
    "    search_queries: list = Field(None, description=\"Search queries for retrieval.\")\n",
    "\n",
    "class LearningVerification(BaseModel):\n",
    "    \"\"\"Structure for verification results\"\"\"\n",
    "    understanding_level: float = Field(..., description=\"Understanding level of the student to the problem.\")\n",
    "    feedback: str\n",
    "    suggestions: List[str]\n",
    "    context_alignment: bool\n",
    "\n",
    "class FeynmanTeaching(BaseModel):\n",
    "    \"\"\"Structure for Feynman teaching method\"\"\"\n",
    "    simplified_explanation: str\n",
    "    key_concepts: List[str]\n",
    "    analogies: List[str]\n",
    "\n",
    "class QuestionOutput(BaseModel):\n",
    "    \"\"\"Structure for question generation output\"\"\"\n",
    "    question: str\n",
    "\n",
    "class InContext(BaseModel):\n",
    "    \"\"\"Structure for context verification\"\"\"\n",
    "    is_in_context: str = Field(..., description=\"Yes or No\")\n",
    "\n",
    "\n",
    "################################\n",
    "# Learning State Definition\n",
    "################################\n",
    "class LearningtState(TypedDict):\n",
    "    topic: str\n",
    "    goals: List[Goals]\n",
    "    context: str\n",
    "    context_chunks: Annotated[list, operator.add]\n",
    "    context_key: str\n",
    "    search_queries: SearchQuery\n",
    "    checkpoints: Checkpoints\n",
    "    verifications: LearningVerification\n",
    "    teachings: FeynmanTeaching\n",
    "    current_checkpoint: int\n",
    "    current_question: QuestionOutput\n",
    "    current_answer: str\n",
    "\n",
    "\n",
    "################################\n",
    "# Helper Functions\n",
    "################################\n",
    "def extract_content_from_chunks(chunks):\n",
    "    \"\"\"Extract and combine content from chunks with splits attribute.\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of chunk objects that may contain splits attribute\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined content from all chunks joined with newlines\n",
    "    \"\"\"\n",
    "    content = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if hasattr(chunk, 'splits') and chunk.splits:\n",
    "            chunk_content = ' '.join(chunk.splits)\n",
    "            content.append(chunk_content)\n",
    "    \n",
    "    return '\\n'.join(content)\n",
    "\n",
    "def format_checkpoints_as_message(checkpoints: Checkpoints) -> str:\n",
    "    \"\"\"Convert Checkpoints object to a formatted string for the message.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints (Checkpoints): Checkpoints object containing learning checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string containing numbered checkpoints with descriptions and criteria\n",
    "    \"\"\"\n",
    "    message = \"Here are the learning checkpoints:\\n\\n\"\n",
    "    for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "        message += f\"Checkpoint {i}:\\n\"\n",
    "        message += f\"Description: {checkpoint.description}\\n\"\n",
    "        message += \"Success Criteria:\\n\"\n",
    "        for criterion in checkpoint.criteria:\n",
    "            message += f\"- {criterion}\\n\"\n",
    "    return message\n",
    "\n",
    "def generate_checkpoint_message(checks: List[LearningCheckpoint]) -> HumanMessage:\n",
    "    \"\"\"Generate a formatted message for learning checkpoints that need context.\n",
    "    \n",
    "    Args:\n",
    "        checks (List[LearningCheckpoint]): List of learning checkpoint objects\n",
    "        \n",
    "    Returns:\n",
    "        HumanMessage: Formatted message containing checkpoint descriptions, criteria and \n",
    "                     verification methods, ready for context search\n",
    "    \"\"\"\n",
    "    formatted_checks = []\n",
    "    \n",
    "    for check in checks:\n",
    "        checkpoint_text = f\"\"\"\n",
    "        Description: {check.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f'- {criterion}' for criterion in check.criteria)}\n",
    "        Verification Method: {check.verification}\n",
    "        \"\"\"    # chr(10)即'\\n'\n",
    "        formatted_checks.append(checkpoint_text)\n",
    "    \n",
    "    all_checks = \"\\n---\\n\".join(formatted_checks)\n",
    "    \n",
    "    checkpoints_message = HumanMessage(content=f\"\"\"The following learning checkpoints need additional context:\n",
    "        {all_checks}\n",
    "        \n",
    "        Please generate search queries to find relevant information.\"\"\")\n",
    "    \n",
    "    return checkpoints_message\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "# Prompts\n",
    "################################\n",
    "# 根据学习材料，生成学习检查点\n",
    "learning_checkpoints_generator = SystemMessage(content=\"\"\"You will be given a learning topic title and learning objectives.\n",
    "Your goal is to generate clear learning checkpoints that will help verify understanding and progress through the topic.\n",
    "The output should be in the following dictionary structure:\n",
    "checkpoint \n",
    "-> description (level checkpoint description)\n",
    "-> criteria\n",
    "-> verification (How to verify this checkpoint (Feynman Methods))\n",
    "Requirements for each checkpoint:\n",
    "- Description should be clear and concise\n",
    "- Criteria should be specific and measurable (3-5 items)\n",
    "- Verification method should be practical and appropriate for the level\n",
    "- Verification will be checked by language model, so it must by in natural language\n",
    "- All elements should align with the learning objectives\n",
    "- Use action verbs and clear language\n",
    "Ensure all checkpoints progress logically from foundation to mastery.\n",
    "IMPORTANT - ANSWER ONLY 3 CHECKPOINTS\"\"\")\n",
    "\n",
    "# 给定检查点，生成一条检索命令，用于查询该检查点的达成标准\n",
    "checkpoint_based_query_generator = SystemMessage(content=\"\"\"You will be given learning checkpoints for a topic.\n",
    "Your goal is to generate search queries that will retrieve content matching each checkpoint's requirements from retrieval systems or web search.\n",
    "Follow these steps:\n",
    "1. Analyze each learning checkpoint carefully\n",
    "2. For each checkpoint, generate ONE targeted search query that will retrieve:\n",
    "   - Content for checkpoint verification\n",
    "IMPORTANT: you should give me a structured answer, where the content string is in a single array, \n",
    "and the string is surrounded by quotation mark, i.e. format your answer like this: [\"the content\"]\n",
    "\"\"\")\n",
    "\n",
    "# 给定一个标准及其上下文，检查该标准是否被上下文回答\n",
    "validate_context = SystemMessage(content=\"\"\"You will be given a learning criteria and context.\n",
    "Check if the the criteria could be answered using the context.\n",
    "Always answer YES or NO\"\"\")\n",
    "\n",
    "# 给定检查点、成功标准、检测方法，生成一个问题，能够用于测验学生是否达成该检查点的要求\n",
    "question_generator = SystemMessage(content=\"\"\"You will be given a checkpoint description, success criteria, and verification method.\n",
    "Your goal is to generate an appropriate question that aligns with the checkpoint's verification requirements.\n",
    "The question should:\n",
    "1. Follow the specified verification method\n",
    "2. Cover all success criteria\n",
    "3. Encourage demonstration of understanding\n",
    "4. Be clear and specific\n",
    "Output should be a single, well-formulated question that effectively tests the checkpoint's learning objectives.\"\"\")\n",
    "\n",
    "# 给定学生的回答，分析其是否到达了检查点的标准\n",
    "answer_verifier = SystemMessage(content=\"\"\"You will be given a student's answer, question, checkpoint details, and relevant context.\n",
    "Your goal is to analyze the answer against the checkpoint criteria and provided context.\n",
    "Analyze considering:\n",
    "1. Alignment with verification method specified\n",
    "2. Coverage of all success criteria\n",
    "3. Use of relevant concepts from context\n",
    "4. Depth and accuracy of understanding\n",
    "Output should include:\n",
    "- understanding_level: float between 0 and 1\n",
    "- feedback: detailed explanation of the assessment\n",
    "- suggestions: list of specific improvements\n",
    "- context_alignment: boolean indicating if the answer aligns with provided context\"\"\")\n",
    "\n",
    "# 给定检测结果、学习的上下文，给学生提出还需加强的知识点（用费曼学习法）\n",
    "feynman_teacher = SystemMessage(content=\"\"\"You will be given verification results, checkpoint criteria, and learning context.\n",
    "Your goal is to create a Feynman-style teaching explanation for concepts that need reinforcement.\n",
    "The explanation should include:\n",
    "1. Simplified explanation without technical jargon\n",
    "2. Concrete, relatable analogies\n",
    "3. Key concepts to remember\n",
    "Output should follow the Feynman technique:\n",
    "- simplified_explanation: clear, jargon-free explanation\n",
    "- key_concepts: list of essential points\n",
    "- analogies: list of relevant, concrete comparisons\n",
    "Focus on making complex ideas accessible and memorable.\"\"\")\n",
    "\n",
    "\n",
    "################################\n",
    "# Context Storage\n",
    "################################\n",
    "class ContextStore:\n",
    "    \"\"\"Store for managing context chunks and their embeddings in memory.\n",
    "    \n",
    "    A class that provides storage and retrieval of context data using an in-memory store.\n",
    "    Each context entry consists of context chunks and their corresponding embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize ContextStore with an empty in-memory store.\"\"\"\n",
    "        self.store = InMemoryStore()\n",
    "        \n",
    "    def save_context(self, context_chunks: list, embeddings: list, key: str = None):\n",
    "        \"\"\"Save context chunks and their embeddings to the store.\n",
    "        \n",
    "        Args:\n",
    "            context_chunks (list): List of context chunk objects\n",
    "            embeddings (list): List of corresponding embeddings for the chunks\n",
    "            key (str, optional): Custom key for storing the context. Defaults to None,\n",
    "                               in which case a UUID is generated.\n",
    "            \n",
    "        Returns:\n",
    "            str: The key used to store the context\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        \n",
    "        if key is None:\n",
    "            key = str(uuid.uuid4())\n",
    "            \n",
    "        value = {\n",
    "            \"chunks\": context_chunks,\n",
    "            \"embeddings\": embeddings\n",
    "        }\n",
    "        \n",
    "        self.store.put(namespace, key, value)\n",
    "        return key\n",
    "        \n",
    "    def get_context(self, context_key: str):\n",
    "        \"\"\"Retrieve context data from the store using a key.\n",
    "        \n",
    "        Args:\n",
    "            context_key (str): The key used to store the context\n",
    "            \n",
    "        Returns:\n",
    "            dict: The stored context value containing chunks and embeddings\n",
    "        \"\"\"\n",
    "        namespace = (\"context\",)\n",
    "        memory = self.store.get(namespace, context_key)\n",
    "        return memory.value\n",
    "\n",
    "\n",
    "################################\n",
    "# Learning Verification & Support\n",
    "################################\n",
    "# 调用模型，根据检查点，生成一条query\n",
    "def generate_query(state: LearningtState):\n",
    "    \"\"\"Generates search queries based on learning checkpoints from current state.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(SearchQuery) \n",
    "    checkpoints_message = HumanMessage(content=format_checkpoints_as_message(state['checkpoints']))  \n",
    "    messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "    search_queries = structured_llm.invoke(messages)\n",
    "    return {\"search_queries\": search_queries}\n",
    "\n",
    "# \n",
    "def search_web(state: LearningtState):\n",
    "    \"\"\"Retrieves and processes web search results based on search queries.\"\"\"\n",
    "    search_queries = state[\"search_queries\"].search_queries\n",
    "    \n",
    "    all_search_docs = []\n",
    "    for query in search_queries:\n",
    "        search_docs = tavily_search.invoke(query)\n",
    "        all_search_docs.extend(search_docs)\n",
    "    \n",
    "    formatted_search_docs = [\n",
    "        f'Context: {doc[\"content\"]}\\n Source: {doc[\"url\"]}\\n'\n",
    "        for doc in all_search_docs\n",
    "    ]\n",
    "\n",
    "    chunk_embeddings = embeddings.embed_documents(formatted_search_docs)\n",
    "    context_key = context_store.save_context(\n",
    "        formatted_search_docs,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    \n",
    "    return {\"context_chunks\": formatted_search_docs}\n",
    "\n",
    "def generate_checkpoints(state: LearningtState):\n",
    "    \"\"\"Creates learning checkpoints based on given topic and goals.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(Checkpoints)\n",
    "    messages = [\n",
    "        learning_checkpoints_generator,\n",
    "        HumanMessage(content=f\"Topic: {state['topic']}\\nGoals: {', '.join(str(goal) for goal in state['goals'])}\"),\n",
    "    ]\n",
    "    checkpoints = structured_llm.invoke(messages)\n",
    "    return {\"checkpoints\": checkpoints}\n",
    "\n",
    "def chunk_context(state: LearningtState):\n",
    "    \"\"\"Splits context into manageable chunks and generates their embeddings.\"\"\"\n",
    "    encoder = OpenAIEncoder(name=\"text-embedding-3-large\", openai_base_url=\"https://chatapi.littlewheat.com/v1\")\n",
    "    chunker = StatisticalChunker(\n",
    "        encoder=encoder,\n",
    "        min_split_tokens=128,\n",
    "        max_split_tokens=512\n",
    "    )\n",
    "    \n",
    "    chunks = chunker([state['context']])\n",
    "    content = []\n",
    "    for chunk in chunks:\n",
    "        content.append(extract_content_from_chunks(chunk))\n",
    "\n",
    "    chunk_embeddings = embeddings.embed_documents(content)\n",
    "    context_key = context_store.save_context(\n",
    "        content,\n",
    "        chunk_embeddings,\n",
    "        key=state.get('context_key')\n",
    "    )\n",
    "    return {\"context_chunks\": content, \"context_key\": context_key}\n",
    "\n",
    "def context_validation(state: LearningtState):\n",
    "    \"\"\"Validates context coverage against checkpoint criteria using stored embeddings.\"\"\"\n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    checks = []\n",
    "    structured_llm = llm.with_structured_output(InContext)\n",
    "    \n",
    "    for checkpoint in state['checkpoints'].checkpoints:\n",
    "        query = embeddings.embed_query(checkpoint.verification)\n",
    "        \n",
    "        similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "        top_3_indices = sorted(range(len(similarities)), \n",
    "                             key=lambda i: similarities[i], \n",
    "                             reverse=True)[:3]\n",
    "        relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "        \n",
    "        messages = [\n",
    "            validate_context,\n",
    "            HumanMessage(content=f\"\"\"\n",
    "            Criteria:\n",
    "            {chr(10).join(f\"- {c}\" for c in checkpoint.criteria)}\n",
    "            \n",
    "            Context:\n",
    "            {chr(10).join(relevant_chunks)}\n",
    "            \"\"\")\n",
    "        ]\n",
    "        \n",
    "        response = structured_llm.invoke(messages)\n",
    "        if response.is_in_context.lower() == \"no\":\n",
    "            checks.append(checkpoint)\n",
    "    \n",
    "    if checks:\n",
    "        structured_llm = llm.with_structured_output(SearchQuery)\n",
    "        checkpoints_message = generate_checkpoint_message(checks)\n",
    "        \n",
    "        messages = [checkpoint_based_query_generator, checkpoints_message]\n",
    "        search_queries = structured_llm.invoke(messages)\n",
    "        return {\"search_queries\": search_queries}\n",
    "    \n",
    "    return {\"search_queries\": None}\n",
    "\n",
    "def generate_question(state: LearningtState):\n",
    "    \"\"\"Generates assessment questions based on current checkpoint verification requirements.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(QuestionOutput)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        question_generator,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Generate an appropriate verification question.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    question_output = structured_llm.invoke(messages)\n",
    "    return {\"current_question\": question_output.question}\n",
    "\n",
    "def verify_answer(state: LearningtState):\n",
    "    \"\"\"Evaluates user answers against checkpoint criteria using relevant context chunks.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(LearningVerification)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    context = context_store.get_context(state['context_key'])\n",
    "    chunks = context['chunks']\n",
    "    chunk_embeddings = context['embeddings']\n",
    "    \n",
    "    query = embeddings.embed_query(checkpoint_info.verification)\n",
    "    \n",
    "    similarities = cosine_similarity([query], chunk_embeddings)[0]\n",
    "    top_3_indices = sorted(range(len(similarities)), \n",
    "                         key=lambda i: similarities[i], \n",
    "                         reverse=True)[:3]\n",
    "    relevant_chunks = [chunks[i] for i in top_3_indices]\n",
    "    \n",
    "    messages = [\n",
    "        answer_verifier,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Question: {state['current_question']}\n",
    "        Answer: {state['current_answer']}\n",
    "        \n",
    "        Checkpoint Description: {checkpoint_info.description}\n",
    "        Success Criteria:\n",
    "        {chr(10).join(f\"- {c}\" for c in checkpoint_info.criteria)}\n",
    "        Verification Method: {checkpoint_info.verification}\n",
    "        \n",
    "        Context:\n",
    "        {chr(10).join(relevant_chunks)}\n",
    "        \n",
    "        Assess the answer.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    verification = structured_llm.invoke(messages)\n",
    "    return {\"verifications\": verification}\n",
    "    \n",
    "def teach_concept(state: LearningtState):\n",
    "    \"\"\"Creates simplified Feynman-style explanations for concepts that need reinforcement.\"\"\"\n",
    "    structured_llm = llm.with_structured_output(FeynmanTeaching)\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    checkpoint_info = state['checkpoints'].checkpoints[current_checkpoint]\n",
    "    \n",
    "    messages = [\n",
    "        feynman_teacher,\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Criteria: {checkpoint_info.criteria}\n",
    "        Verification: {state['verifications']}\n",
    "        \n",
    "        Context:\n",
    "        {state['context_chunks']}\n",
    "        \n",
    "        Create a Feynman teaching explanation.\"\"\")\n",
    "    ]\n",
    "    \n",
    "    teaching = structured_llm.invoke(messages)\n",
    "    return {\"teachings\": teaching}\n",
    "\n",
    "\n",
    "################################\n",
    "# Helper State Management\n",
    "################################\n",
    "def user_answer(state: LearningtState):\n",
    "    \"\"\"Placeholder for handling user's answer input.\"\"\"\n",
    "    pass\n",
    "\n",
    "def next_checkpoint(state: LearningtState):\n",
    "    \"\"\"Advances to the next checkpoint in the learning sequence.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint'] + 1\n",
    "    return {'current_checkpoint': current_checkpoint}\n",
    "\n",
    "\n",
    "################################\n",
    "# Routing Logic\n",
    "################################\n",
    "def route_context(state: LearningtState):\n",
    "    \"\"\"Determines whether to process existing context or generate new search queries.\"\"\"\n",
    "    if state.get(\"context\"):\n",
    "        return 'chunk_context'\n",
    "    return 'generate_query'\n",
    "\n",
    "def route_verification(state: LearningtState):\n",
    "    \"\"\"Determines next step based on verification results and checkpoint progress.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    \n",
    "    if state['verifications'].understanding_level < 0.7:\n",
    "        return 'teach_concept'\n",
    "        \n",
    "    if current_checkpoint + 1 < len(state['checkpoints'].checkpoints):\n",
    "        return 'next_checkpoint'\n",
    "    \n",
    "    return END\n",
    "\n",
    "def route_teaching(state: LearningtState):\n",
    "    \"\"\"Routes to next checkpoint or ends session after teaching intervention.\"\"\"\n",
    "    current_checkpoint = state['current_checkpoint']\n",
    "    if current_checkpoint + 1 < len(state['checkpoints'].checkpoints):\n",
    "        return 'next_checkpoint'\n",
    "    return END\n",
    "\n",
    "def route_search(state: LearningtState):\n",
    "    \"\"\"Directs flow between question generation and web search based on query status.\"\"\"\n",
    "    if state['search_queries'] is None:\n",
    "        return \"generate_question\"\n",
    "    return \"search_web\"\n",
    "        \n",
    "searcher = StateGraph(LearningtState)\n",
    "memory = MemorySaver()\n",
    "context_store = ContextStore()\n",
    "\n",
    "searcher.add_node(\"generate_query\", generate_query)\n",
    "searcher.add_node(\"search_web\", search_web)\n",
    "searcher.add_node(\"chunk_context\", chunk_context)\n",
    "searcher.add_node(\"context_validation\", context_validation)\n",
    "searcher.add_node(\"generate_checkpoints\", generate_checkpoints)\n",
    "searcher.add_node(\"generate_question\", generate_question)\n",
    "searcher.add_node(\"next_checkpoint\", next_checkpoint)\n",
    "searcher.add_node(\"user_answer\", user_answer)\n",
    "searcher.add_node(\"verify_answer\", verify_answer)\n",
    "searcher.add_node(\"teach_concept\", teach_concept)\n",
    "\n",
    "# Flow\n",
    "searcher.add_edge(START, \"generate_checkpoints\")\n",
    "searcher.add_conditional_edges('generate_checkpoints', route_context,['chunk_context', 'generate_query'])\n",
    "searcher.add_edge(\"generate_query\", \"search_web\")\n",
    "searcher.add_edge(\"search_web\", \"generate_question\")\n",
    "searcher.add_edge(\"chunk_context\", 'context_validation')\n",
    "searcher.add_conditional_edges('context_validation', route_search,['search_web', 'generate_question'])\n",
    "\n",
    "searcher.add_edge(\"generate_question\", \"user_answer\")\n",
    "searcher.add_edge(\"user_answer\", \"verify_answer\")\n",
    "searcher.add_conditional_edges(\n",
    "    \"verify_answer\",\n",
    "    route_verification,\n",
    "    {\n",
    "        \"next_checkpoint\": \"next_checkpoint\",\n",
    "        \"teach_concept\": \"teach_concept\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "searcher.add_conditional_edges(\n",
    "    \"teach_concept\",\n",
    "    route_teaching,\n",
    "    {\n",
    "        \"next_checkpoint\": \"next_checkpoint\",\n",
    "        END: END\n",
    "        }\n",
    ")\n",
    "searcher.add_edge(\"next_checkpoint\", \"generate_question\")\n",
    "\n",
    "graph = searcher.compile(interrupt_after=[\"generate_checkpoints\"], interrupt_before=[\"user_answer\"], checkpointer=memory)\n",
    "\n",
    "# display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee853af9-d40f-44ff-a1a0-b688b10c5485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# 学习医学笔记：贫血\n",
    "\n",
    "################################\n",
    "# Pretty print helper functions\n",
    "################################\n",
    "def print_checkpoints(event):\n",
    "    \"\"\"Pretty print checkpoints information with improved visual formatting\"\"\"\n",
    "    checkpoints = event.get('checkpoints', '')\n",
    "    if checkpoints:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"🎯 LEARNING CHECKPOINTS OVERVIEW\".center(80))\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        for i, checkpoint in enumerate(checkpoints.checkpoints, 1):\n",
    "            # Checkpoint header with number\n",
    "            print(f\"📍 CHECKPOINT #{i}\".center(80))\n",
    "            print(\"─\" * 80 + \"\\n\")\n",
    "            \n",
    "            # Description section with text wrapping\n",
    "            print(\"📝 Description:\")\n",
    "            print(\"─\" * 40)\n",
    "            words = checkpoint.description.split()\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 70:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    print(f\"  {' '.join(current_line)}\")\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                print(f\"  {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Success Criteria section\n",
    "            print(\"✅ Success Criteria:\")\n",
    "            print(\"─\" * 40)\n",
    "            for j, criterion in enumerate(checkpoint.criteria, 1):\n",
    "                # Wrap each criterion text\n",
    "                words = criterion.split()\n",
    "                current_line = []\n",
    "                current_length = 0\n",
    "                first_line = True\n",
    "                \n",
    "                for word in words:\n",
    "                    if current_length + len(word) + 1 <= 66:  # Shorter width to account for numbering\n",
    "                        current_line.append(word)\n",
    "                        current_length += len(word) + 1\n",
    "                    else:\n",
    "                        if first_line:\n",
    "                            print(f\"  {j}. {' '.join(current_line)}\")\n",
    "                            first_line = False\n",
    "                        else:\n",
    "                            print(f\"     {' '.join(current_line)}\")\n",
    "                        current_line = [word]\n",
    "                        current_length = len(word)\n",
    "                \n",
    "                if current_line:\n",
    "                    if first_line:\n",
    "                        print(f\"  {j}. {' '.join(current_line)}\")\n",
    "                    else:\n",
    "                        print(f\"     {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Verification Method section\n",
    "            print(\"🔍 Verification Method:\")\n",
    "            print(\"─\" * 40)\n",
    "            words = checkpoint.verification.split()\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 70:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    print(f\"  {' '.join(current_line)}\")\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                print(f\"  {' '.join(current_line)}\")\n",
    "            print()\n",
    "            \n",
    "            # Separator between checkpoints\n",
    "            if i < len(checkpoints.checkpoints):\n",
    "                print(\"~\" * 80 + \"\\n\")\n",
    "        \n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "def print_verification_results(event):\n",
    "    \"\"\"Pretty print verification results with improved formatting\"\"\"\n",
    "    verifications = event.get('verifications', '')\n",
    "    if verifications:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"📊 VERIFICATION RESULTS\".center(50))\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "        # Understanding Level with visual bar\n",
    "        understanding = verifications.understanding_level\n",
    "        bar_length = 20\n",
    "        filled_length = int(understanding * bar_length)\n",
    "        bar = \"█\" * filled_length + \"░\" * (bar_length - filled_length)\n",
    "        \n",
    "        print(f\"📈 Understanding Level: [{bar}] {understanding * 100:.1f}%\\n\")\n",
    "        \n",
    "        # Feedback section\n",
    "        print(\"💡 Feedback:\")\n",
    "        print(f\"{verifications.feedback}\\n\")\n",
    "        \n",
    "        # Suggestions section\n",
    "        print(\"🎯 Suggestions:\")\n",
    "        for i, suggestion in enumerate(verifications.suggestions, 1):\n",
    "            print(f\"  {i}. {suggestion}\")\n",
    "        print()\n",
    "        \n",
    "        # Context Alignment\n",
    "        print(\"🔍 Context Alignment:\")\n",
    "        print(f\"{verifications.context_alignment}\\n\")\n",
    "        \n",
    "        print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "def print_teaching_results(event):\n",
    "    \"\"\"Pretty print Feynman teaching results with improved formatting\"\"\"\n",
    "    teachings = event.get('teachings', '')\n",
    "    if teachings:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"🎓 FEYNMAN TEACHING EXPLANATION\".center(70))\n",
    "        print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "        # Simplified Explanation section\n",
    "        print(\"📚 SIMPLIFIED EXPLANATION:\")\n",
    "        print(\"─\" * 30)\n",
    "        # Split explanation into paragraphs for better readability\n",
    "        paragraphs = teachings.simplified_explanation.split('\\n')\n",
    "        for paragraph in paragraphs:\n",
    "            # Wrap text at 60 characters for better readability\n",
    "            words = paragraph.split()\n",
    "            lines = []\n",
    "            current_line = []\n",
    "            current_length = 0\n",
    "            \n",
    "            for word in words:\n",
    "                if current_length + len(word) + 1 <= 60:\n",
    "                    current_line.append(word)\n",
    "                    current_length += len(word) + 1\n",
    "                else:\n",
    "                    lines.append(' '.join(current_line))\n",
    "                    current_line = [word]\n",
    "                    current_length = len(word)\n",
    "            \n",
    "            if current_line:\n",
    "                lines.append(' '.join(current_line))\n",
    "            \n",
    "            for line in lines:\n",
    "                print(f\"{line}\")\n",
    "            print()\n",
    "        \n",
    "        # Key Concepts section\n",
    "        print(\"💡 KEY CONCEPTS:\")\n",
    "        print(\"─\" * 30)\n",
    "        for i, concept in enumerate(teachings.key_concepts, 1):\n",
    "            print(f\"  {i}. {concept}\")\n",
    "        print()\n",
    "        \n",
    "        # Analogies section\n",
    "        print(\"🔄 ANALOGIES & EXAMPLES:\")\n",
    "        print(\"─\" * 30)\n",
    "        for i, analogy in enumerate(teachings.analogies, 1):\n",
    "            print(f\"  {i}. {analogy}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "        \n",
    "# note = \"\"\"Anemia: A Comprehensive Overview\n",
    "# Definition\n",
    "# Anemia is a medical condition characterized by a decrease in the total number of red blood cells (RBCs) or hemoglobin in the blood. This reduction leads to a diminished ability to carry oxygen to the body's tissues, affecting overall body function and health.\n",
    "# Blood Components and Their Role\n",
    "# Red blood cells, also known as erythrocytes, are fundamental components of blood that carry oxygen throughout the body. These cells contain hemoglobin, an iron-containing protein that gives blood its characteristic red color and is responsible for oxygen transport. The typical lifespan of a red blood cell is approximately 120 days, after which it must be replaced by new cells produced in the bone marrow.\n",
    "# Types of Anemia\n",
    "# Iron Deficiency Anemia represents the most prevalent form of anemia worldwide. It occurs due to insufficient iron intake or absorption, particularly affecting pregnant women, growing children, menstruating women, and individuals with poor nutritional intake.\n",
    "# Vitamin Deficiency Anemia develops when the body lacks sufficient amounts of vitamin B12 or folate (vitamin B9). This deficiency can stem from dietary inadequacies or problems with nutrient absorption in the digestive system.\n",
    "# Aplastic Anemia, though rare, presents a serious condition where the bone marrow fails to produce adequate blood cells. This form can be either inherited through genetic factors or acquired through various environmental causes or medical conditions.\n",
    "# Hemolytic Anemia occurs when red blood cells are destroyed at a rate faster than the body can replace them. This condition may be inherited through genetic factors or acquired through various external causes.\n",
    "# Clinical Manifestations\n",
    "# Anemia manifests through various symptoms including persistent fatigue and weakness. Patients often present with pale or yellowish skin, experience shortness of breath, and may suffer from dizziness. Additional symptoms include irregular heartbeat patterns, frequent headaches, cold extremities, and occasional chest pain.\n",
    "# Diagnostic Approach\n",
    "# Diagnosis begins with a thorough physical examination by a healthcare provider. Blood tests form the cornerstone of diagnosis, including a Complete Blood Count (CBC), assessment of iron levels, vitamin B12 measurement, and folate level determination. These tests help identify the specific type of anemia and guide appropriate treatment.\n",
    "# Treatment Strategies\n",
    "# Dietary modification serves as a fundamental treatment approach. This involves increasing consumption of iron-rich foods such as red meat, dark leafy vegetables, legumes, and iron-fortified cereals.\n",
    "# Supplementation often proves necessary and may include iron supplements, vitamin B12, or folic acid, depending on the underlying cause of anemia.\n",
    "# Medical interventions become necessary in severe cases. Blood transfusions may be required for severe anemia, while bone marrow transplantation might be considered for cases of aplastic anemia.\n",
    "# Preventive Measures\n",
    "# Prevention centers on maintaining a balanced diet rich in essential nutrients, particularly iron, vitamin B12, folate, and vitamin C, which enhances iron absorption. Regular medical check-ups allow for early detection and intervention.\n",
    "# Certain populations require special attention regarding prevention. These include pregnant women, menstruating women, growing children, individuals following vegetarian or vegan diets, and athletes who may have increased nutritional demands.\n",
    "# Potential Complications\n",
    "# Untreated anemia can lead to several serious complications. These include severe fatigue that impacts daily activities, complications during pregnancy, cardiovascular problems, depression, and cognitive difficulties that may affect work or school performance.\n",
    "# Clinical Significance\n",
    "# Anemia often serves as an indicator of other underlying medical conditions. Therefore, early detection and appropriate treatment prove crucial for optimal outcomes. Different forms of anemia require specific treatment approaches, and regular monitoring may be necessary to ensure treatment effectiveness.\"\"\"\n",
    "\n",
    "import fitz\n",
    "def pdf_to_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")  # 仅提取文本\n",
    "    return text\n",
    "\n",
    "note = pdf_to_text(\"死锁知识总结.pdf\")\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435eebc1-5d60-4dcf-8733-a30a47171107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                        🎯 LEARNING CHECKPOINTS OVERVIEW                         \n",
      "================================================================================\n",
      "\n",
      "                                📍 CHECKPOINT #1                                 \n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "📝 Description:\n",
      "────────────────────────────────────────\n",
      "  理解死锁的基本概念和必要条件\n",
      "\n",
      "✅ Success Criteria:\n",
      "────────────────────────────────────────\n",
      "  1. 能够定义死锁\n",
      "  2. 能够列出死锁的四个必要条件\n",
      "  3. 能够解释每个必要条件的作用\n",
      "\n",
      "🔍 Verification Method:\n",
      "────────────────────────────────────────\n",
      "  请解释什么是死锁，并列出并解释死锁的四个必要条件。\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "                                📍 CHECKPOINT #2                                 \n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "📝 Description:\n",
      "────────────────────────────────────────\n",
      "  能够识别和分析死锁发生的场景\n",
      "\n",
      "✅ Success Criteria:\n",
      "────────────────────────────────────────\n",
      "  1. 能够识别可能导致死锁的代码片段\n",
      "  2. 能够分析死锁发生的具体原因\n",
      "  3. 能够描述死锁发生的流程\n",
      "\n",
      "🔍 Verification Method:\n",
      "────────────────────────────────────────\n",
      "  请分析以下代码片段，指出是否存在死锁风险，并解释原因。\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "                                📍 CHECKPOINT #3                                 \n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "📝 Description:\n",
      "────────────────────────────────────────\n",
      "  掌握死锁的预防和避免策略\n",
      "\n",
      "✅ Success Criteria:\n",
      "────────────────────────────────────────\n",
      "  1. 能够列出常见的死锁预防策略\n",
      "  2. 能够解释每种预防策略的原理\n",
      "  3. 能够应用死锁避免算法\n",
      "\n",
      "🔍 Verification Method:\n",
      "────────────────────────────────────────\n",
      "  请列出并解释三种常见的死锁预防策略，并描述如何使用银行家算法来避免死锁。\n",
      "\n",
      "================================================================================\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\n",
    "\"topic\": \"Anemia\",\n",
    "'goals': ['Im medical student, i want to master the diagnosis of Anemia'],\n",
    "'context': note,\n",
    "'current_checkpoint': 0}\n",
    "\n",
    "initial_input = {\n",
    "\"topic\": \"死锁\",\n",
    "'goals': ['我是一名计算机专业的学生，希望掌握死锁相关的知识'],\n",
    "'context': note,\n",
    "'current_checkpoint': 0}\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"20\"}}\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    print_checkpoints(event)\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91f1daf-ec0b-41c0-8799-a95431de8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints=[LearningCheckpoint(description='理解死锁的基本概念和必要条件', criteria=['能够定义死锁', '能够列出死锁的四个必要条件', '能够解释每个必要条件的作用'], verification='请解释什么是死锁，并列出并解释死锁的四个必要条件。'), LearningCheckpoint(description='能够识别和分析死锁发生的场景', criteria=['能够识别可能导致死锁的代码片段', '能够分析死锁发生的具体原因', '能够描述死锁发生的流程'], verification='请分析以下代码片段，指出是否存在死锁风险，并解释原因。'), LearningCheckpoint(description='掌握死锁的预防和避免策略', criteria=['能够列出常见的死锁预防策略', '能够解释每种预防策略的原理', '能够应用死锁避免算法'], verification='请列出并解释三种常见的死锁预防策略，并描述如何使用银行家算法来避免死锁。')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab269941049433491b2f09bd84f0a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(HTML(value='<h3 style=\"margin: 0;\">Checkpoint 1</h3>'), Checkbox(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pydantic import BaseModel\n",
    "\n",
    "def create_checkpoint_editor(checkpoints_model: Checkpoints):\n",
    "    \"\"\"\n",
    "    Creates an interactive checkpoint editor using a Pydantic model.\n",
    "    \n",
    "    Args:\n",
    "        checkpoints_model: Pydantic model of Checkpoints class\n",
    "    \"\"\"\n",
    "    # Convert to list of dictionaries for easier editing\n",
    "    checkpoints = [cp.model_dump() for cp in checkpoints_model.checkpoints]\n",
    "    checkpoints_widgets = []\n",
    "    accepted_checkpoints = []\n",
    "    \n",
    "    def create_criterion_widget(checkpoint_index: int, criterion_value: str = \"\", criterion_index: int = None):\n",
    "        \"\"\"Creates a widget for a single criterion with a delete button\"\"\"\n",
    "        criterion_container = widgets.HBox([\n",
    "            widgets.Text(\n",
    "                value=criterion_value,\n",
    "                description=f'{criterion_index + 1}.' if criterion_index is not None else 'New',\n",
    "                layout=widgets.Layout(width='85%')\n",
    "            ),\n",
    "            widgets.Button(\n",
    "                description='Delete',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(width='15%')\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        def on_criterion_change(change):\n",
    "            nonlocal criterion_index\n",
    "            if criterion_index is not None:\n",
    "                checkpoints[checkpoint_index]['criteria'][criterion_index] = change['new']\n",
    "        \n",
    "        def remove_criterion(b):\n",
    "            if criterion_index is not None:\n",
    "                checkpoints[checkpoint_index]['criteria'].pop(criterion_index)\n",
    "                update_checkpoint_widget(checkpoint_index)\n",
    "        \n",
    "        criterion_container.children[0].observe(on_criterion_change, names='value')\n",
    "        criterion_container.children[1].on_click(remove_criterion)\n",
    "        \n",
    "        return criterion_container\n",
    "    \n",
    "    def create_checkpoint_widget(checkpoint: dict, index: int):\n",
    "        \"\"\"Creates a widget for a single checkpoint\"\"\"\n",
    "        \n",
    "        def on_accept_change(change):\n",
    "            if change['new']:\n",
    "                accepted_checkpoints.append(index)\n",
    "            else:\n",
    "                if index in accepted_checkpoints:\n",
    "                    accepted_checkpoints.remove(index)\n",
    "        \n",
    "        def on_description_change(change):\n",
    "            checkpoints[index]['description'] = change['new']\n",
    "        \n",
    "        def on_verification_change(change):\n",
    "            checkpoints[index]['verification'] = change['new']\n",
    "        \n",
    "        def add_criterion(b):\n",
    "            checkpoints[index]['criteria'].append(\"\")\n",
    "            update_checkpoint_widget(index)\n",
    "        \n",
    "        def remove_checkpoint(b):\n",
    "            checkpoints.pop(index)\n",
    "            update_all_checkpoints()\n",
    "        \n",
    "        # Header with checkbox and delete button\n",
    "        header = widgets.HBox([\n",
    "            widgets.HTML(f'<h3 style=\"margin: 0;\">Checkpoint {index + 1}</h3>'),\n",
    "            widgets.Checkbox(\n",
    "                value=False,\n",
    "                description='Accept',\n",
    "                indent=False,\n",
    "                layout=widgets.Layout(margin='5px 0 0 20px')\n",
    "            ),\n",
    "            widgets.Button(\n",
    "                description='Delete checkpoint',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(margin='0 0 0 20px')\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Description\n",
    "        description = widgets.Textarea(\n",
    "            value=checkpoint['description'],\n",
    "            description='Description:',\n",
    "            layout=widgets.Layout(width='95%', height='60px')\n",
    "        )\n",
    "        \n",
    "        # Criteria\n",
    "        criteria_label = widgets.HTML('<b>Criteria:</b>')\n",
    "        criteria_container = widgets.VBox([\n",
    "            create_criterion_widget(index, criterion, i)\n",
    "            for i, criterion in enumerate(checkpoint['criteria'])\n",
    "        ])\n",
    "        \n",
    "        # Add criterion button\n",
    "        add_criterion_btn = widgets.Button(\n",
    "            description='Add criterion',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        # Verification\n",
    "        verification = widgets.Textarea(\n",
    "            value=checkpoint['verification'],\n",
    "            description='Verification:',\n",
    "            layout=widgets.Layout(width='95%', height='60px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        separator = widgets.HTML('<hr style=\"margin: 20px 0;\">')\n",
    "        \n",
    "        # Combine all elements\n",
    "        checkpoint_widget = widgets.VBox([\n",
    "            header,\n",
    "            description,\n",
    "            criteria_label,\n",
    "            criteria_container,\n",
    "            add_criterion_btn,\n",
    "            verification,\n",
    "            separator\n",
    "        ])\n",
    "        \n",
    "        # Add observers and handlers\n",
    "        header.children[1].observe(on_accept_change, names='value')\n",
    "        header.children[2].on_click(remove_checkpoint)\n",
    "        description.observe(on_description_change, names='value')\n",
    "        verification.observe(on_verification_change, names='value')\n",
    "        add_criterion_btn.on_click(add_criterion)\n",
    "        \n",
    "        return checkpoint_widget\n",
    "    \n",
    "    def update_checkpoint_widget(index: int):\n",
    "        \"\"\"Updates a single checkpoint widget\"\"\"\n",
    "        if 0 <= index < len(checkpoints):\n",
    "            checkpoints_widgets[index] = create_checkpoint_widget(checkpoints[index], index)\n",
    "            update_main_container()\n",
    "    \n",
    "    def update_all_checkpoints():\n",
    "        \"\"\"Updates all checkpoint widgets\"\"\"\n",
    "        nonlocal checkpoints_widgets\n",
    "        checkpoints_widgets = [\n",
    "            create_checkpoint_widget(checkpoint, i)\n",
    "            for i, checkpoint in enumerate(checkpoints)\n",
    "        ]\n",
    "        update_main_container()\n",
    "    \n",
    "    def add_new_checkpoint(b):\n",
    "        \"\"\"Adds a new checkpoint\"\"\"\n",
    "        checkpoints.append({\n",
    "            'description': '',\n",
    "            'criteria': [],\n",
    "            'verification': ''\n",
    "        })\n",
    "        update_all_checkpoints()\n",
    "    \n",
    "    def get_pydantic_model() -> Checkpoints:\n",
    "        \"\"\"Converts the current editor state back to a Pydantic model\"\"\"\n",
    "        return Checkpoints(checkpoints=[\n",
    "            LearningCheckpoint(**checkpoint)\n",
    "            for checkpoint in checkpoints\n",
    "        ])\n",
    "    \n",
    "    # Create initial checkpoint widgets\n",
    "    checkpoints_widgets = [\n",
    "        create_checkpoint_widget(checkpoint, i)\n",
    "        for i, checkpoint in enumerate(checkpoints)\n",
    "    ]\n",
    "    \n",
    "    # Add new checkpoint button\n",
    "    add_checkpoint_btn = widgets.Button(\n",
    "        description='Add checkpoint',\n",
    "        button_style='success',\n",
    "        layout=widgets.Layout(margin='20px 0')\n",
    "    )\n",
    "    add_checkpoint_btn.on_click(add_new_checkpoint)\n",
    "    \n",
    "    # Main container\n",
    "    main_container = widgets.VBox(\n",
    "        checkpoints_widgets + [add_checkpoint_btn],\n",
    "        layout=widgets.Layout(\n",
    "            padding='20px',\n",
    "            border='1px solid #ddd',\n",
    "            border_radius='5px'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def update_main_container():\n",
    "        \"\"\"Updates the main container\"\"\"\n",
    "        main_container.children = tuple(checkpoints_widgets + [add_checkpoint_btn])\n",
    "    \n",
    "    # Add method to container to retrieve data later\n",
    "    main_container.get_model = get_pydantic_model\n",
    "    \n",
    "    return main_container\n",
    "\n",
    "\n",
    "checkpoints = event['checkpoints']\n",
    "print(checkpoints)\n",
    "editor = create_checkpoint_editor(checkpoints)\n",
    "display(editor)\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307c1fb7-7761-48ab-b3d1-3d5f7070eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-14 00:32:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 512. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113575c896dd49c0a459efa202dd2dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请解释什么是死锁，并列出并解释死锁的四个必要条件。\n"
     ]
    }
   ],
   "source": [
    "updated_model = editor.get_model()\n",
    "graph.update_state(thread, {\"checkpoints\": updated_model}, as_node=\"generate_checkpoints\")\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    # Review\n",
    "    current_question = event.get('current_question', '')\n",
    "    if current_question:\n",
    "        print(current_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0633b54a-a0d9-42b0-90ad-8c320603e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('verify_answer',)\n",
      "()\n",
      "('generate_question',)\n",
      "('user_answer',)\n",
      "\n",
      "==================================================\n",
      "              📊 VERIFICATION RESULTS              \n",
      "==================================================\n",
      "\n",
      "📈 Understanding Level: [███████████████░░░░░] 75.0%\n",
      "\n",
      "💡 Feedback:\n",
      "The student has a good understanding of the basic concept of deadlock and has correctly listed the four necessary conditions for deadlock. However, the explanation of each condition is lacking in depth and detail. The student should provide more specific explanations for each condition to demonstrate a deeper understanding.\n",
      "\n",
      "🎯 Suggestions:\n",
      "  1. Provide a more detailed explanation of each of the four necessary conditions for deadlock.\n",
      "  2. Explain how each condition contributes to the occurrence of deadlock.\n",
      "  3. Use examples or scenarios to illustrate the conditions and their impact on deadlock.\n",
      "\n",
      "🔍 Context Alignment:\n",
      "True\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_question = \"\"\"\n",
    "死锁是两个或更多进程在需要相同资源时，由于特殊竞争条件而发生的，陷入等待资源但都无法被满足的情况，发生死锁后，多个进程会陷入永久的等待，无法继续执行。\n",
    "发生死锁的四个必要条件是：互斥、非抢占、占有并等待、循环等待。\n",
    "\"\"\"# input(\"Answer the question above: \")\n",
    "graph.update_state(thread, {\"current_answer\": answer_question}, as_node=\"user_answer\")\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    print(graph.get_state(thread).next)\n",
    "    \n",
    "print_verification_results(event)\n",
    "print_teaching_results(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c87239-15bc-4ad1-b8b9-d97ab41bfd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
